// Modified Wisconsin Card Sorting Task RL Model
// Based on hBayesDM package with improvements for numerical stability
data {
  int<lower=1> N; // Number of subjects
  int<lower=1> T; // Maximum number of trials
  array[N] int<lower=1, upper=T> Tsubj; // Trials per subject
  array[N] int<lower=0, upper=1> holdout; // Holdout indicator
  
  array[N, T] real rew; // Reward values
  array[N, T] real los; // Loss values
  
  array[N, T] int rule_choice; // Rule choices
  array[N, T] int resp_choice; // Response choices
  
  array[N, T] int resp_color; // Color responses
  array[N, T] int resp_shape; // Shape responses
  array[N, T] int resp_number; // Number responses
}
parameters {
  // Group-level parameters
  vector[7] mu_pr; // Group means on probit scale
  vector<lower=0>[7] sigma_pr; // Group standard deviations on probit scale
  
  // Subject-level parameters (non-centered parameterization)
  vector[N] MB_Arew_z; // Model-based reward learning rate
  vector[N] MB_Apun_z; // Model-based punishment learning rate
  vector[N] MB_gamma_z; // Model-based decay rate
  
  vector[N] MF_Arew_z; // Model-free reward learning rate
  vector[N] MF_Apun_z; // Model-free punishment learning rate
  vector[N] MF_gamma_z; // Model-free decay rate
  
  vector[N] temp_z; // Temperature parameter (inverse softmax)
}
transformed parameters {
  // Transform subject-level parameters from z-scores to actual scales
  vector<lower=0, upper=1>[N] MB_Arew;
  vector<lower=0, upper=1>[N] MB_Apun;
  vector<lower=0, upper=1>[N] MB_gamma;
  
  vector<lower=0, upper=1>[N] MF_Arew;
  vector<lower=0, upper=1>[N] MF_Apun;
  vector<lower=0, upper=1>[N] MF_gamma;
  
  vector<lower=0>[N] temp; // Temperature (always positive)
  
  // Group-level means on actual scales
  vector[7] mu; // Group means on actual scales
  
  // Non-centered parameterization for better sampling
  for (i in 1 : N) {
    // Learning rates and decay parameters using inverse logit (sigmoid) transformation
    MB_Arew[i] = inv_logit(mu_pr[1] + sigma_pr[1] * MB_Arew_z[i]);
    MB_Apun[i] = inv_logit(mu_pr[2] + sigma_pr[2] * MB_Apun_z[i]);
    MB_gamma[i] = inv_logit(mu_pr[3] + sigma_pr[3] * MB_gamma_z[i]);
    
    MF_Arew[i] = inv_logit(mu_pr[4] + sigma_pr[4] * MF_Arew_z[i]);
    MF_Apun[i] = inv_logit(mu_pr[5] + sigma_pr[5] * MF_Apun_z[i]);
    MF_gamma[i] = inv_logit(mu_pr[6] + sigma_pr[6] * MF_gamma_z[i]);
    
    // Temperature parameter with exp transformation (more stable than Phi_approx * 5)
    // Using log(1+exp(x)) for numerical stability
    temp[i] = log1p_exp(mu_pr[7] + sigma_pr[7] * temp_z[i]);
  }
  
  // Transform group-level means to actual scales
  for (j in 1 : 6) {
    mu[j] = inv_logit(mu_pr[j]); // Learning rates and decay params
  }
  mu[7] = log1p_exp(mu_pr[7]); // Temperature
}
model {
  // Priors for group-level parameters
  mu_pr ~ normal(0, 1.5); // Less informative prior on probit scale
  sigma_pr ~ normal(0, 0.5); // Half-normal prior instead of Cauchy
  
  // Priors for subject-level parameters (standard normal for z-scores)
  MB_Arew_z ~ std_normal();
  MB_Apun_z ~ std_normal();
  MB_gamma_z ~ std_normal();
  
  MF_Arew_z ~ std_normal();
  MF_Apun_z ~ std_normal();
  MF_gamma_z ~ std_normal();
  
  temp_z ~ std_normal();
  
  // Likelihood
  for (i in 1 : N) {
    if (holdout[i] == 0) {
      // Define values
      vector[4] Qeff; // Effective Q values
      vector[3] QMB; // Model-based Q values
      vector[4] QMF; // Model-free Q values
      vector[3] PEMB; // Model-based prediction error
      vector[4] PEMF; // Model-free prediction error
      
      // Initialize values
      QMB = rep_vector(0.0, 3);
      QMF = rep_vector(0.0, 4);
      
      for (t in 1 : Tsubj[i]) {
        // Calculate effective Q values
        Qeff = rep_vector(-1.0, 4); // Set baseline to -1 for invalid choices
        
        // Reset valid choices to 0
        Qeff[resp_color[i, t]] = 0.0;
        Qeff[resp_shape[i, t]] = 0.0;
        Qeff[resp_number[i, t]] = 0.0;
        
        // Add model-based components
        Qeff[resp_color[i, t]] += QMB[1];
        Qeff[resp_shape[i, t]] += QMB[2];
        Qeff[resp_number[i, t]] += QMB[3];
        
        // Add model-free components
        Qeff += QMF;
        
        // Apply softmax with temperature
        target += categorical_logit_lpmf(resp_choice[i, t] | Qeff / temp[i]);
        
        // Apply decay to both model components
        QMB *= MB_gamma[i];
        QMF *= MF_gamma[i];
        
        // Calculate prediction errors
        PEMB = rep_vector(0.0, 3);
        PEMF = rep_vector(0.0, 4);
        
        real current_outcome = rew[i, t] + los[i, t];
        
        PEMB[rule_choice[i, t]] = current_outcome - QMB[rule_choice[i, t]];
        PEMF[resp_choice[i, t]] = current_outcome - QMF[resp_choice[i, t]];
        
        // Update Q values based on prediction errors
        if (rew[i, t] == 1) {
          // Reward condition
          QMB += MB_Arew[i] * PEMB;
          QMF += MF_Arew[i] * PEMF;
        } else {
          // Punishment condition
          QMB += MB_Apun[i] * PEMB;
          QMF += MF_Apun[i] * PEMF;
        }
      }
    }
  }
}
generated quantities {
  // Group-level parameter means on actual scales  
  real<lower=0, upper=1> mu_MB_Arew = mu[1];
  real<lower=0, upper=1> mu_MB_Apun = mu[2];
  real<lower=0, upper=1> mu_MB_gamma = mu[3];
  
  real<lower=0, upper=1> mu_MF_Arew = mu[4];
  real<lower=0, upper=1> mu_MF_Apun = mu[5];
  real<lower=0, upper=1> mu_MF_gamma = mu[6];
  
  real<lower=0> mu_temp = mu[7];
  
  // For log likelihood calculation and model comparison
  array[N] real log_lik;
  
  // For posterior predictive checks
  array[N, T] int y_pred;
  
  // Initialize all predictions to -1 (invalid value)
  for (i in 1 : N) {
    for (t in 1 : T) {
      y_pred[i, t] = -1;
    }
  }
  
  // Calculate log likelihood and generate predictions
  {
    for (i in 1 : N) {
      vector[4] Qeff;
      vector[3] QMB;
      vector[4] QMF;
      vector[3] PEMB;
      vector[4] PEMF;
      
      // Initialize values
      QMB = rep_vector(0.0, 3);
      QMF = rep_vector(0.0, 4);
      log_lik[i] = 0.0;
      
      for (t in 1 : Tsubj[i]) {
        // Calculate effective Q values
        Qeff = rep_vector(-1.0, 4);
        
        Qeff[resp_color[i, t]] = 0.0;
        Qeff[resp_shape[i, t]] = 0.0;
        Qeff[resp_number[i, t]] = 0.0;
        
        Qeff[resp_color[i, t]] += QMB[1];
        Qeff[resp_shape[i, t]] += QMB[2];
        Qeff[resp_number[i, t]] += QMB[3];
        
        Qeff += QMF;
        
        // Compute log likelihood contribution
        vector[4] softmax_probs = softmax(Qeff / temp[i]);
        log_lik[i] += categorical_lpmf(resp_choice[i, t] | softmax_probs);
        
        // Generate posterior prediction
        y_pred[i, t] = categorical_rng(softmax_probs);
        
        // Apply decay
        QMB *= MB_gamma[i];
        QMF *= MF_gamma[i];
        
        // Calculate prediction errors
        PEMB = rep_vector(0.0, 3);
        PEMF = rep_vector(0.0, 4);
        
        real current_outcome = rew[i, t] + los[i, t];
        
        PEMB[rule_choice[i, t]] = current_outcome - QMB[rule_choice[i, t]];
        PEMF[resp_choice[i, t]] = current_outcome - QMF[resp_choice[i, t]];
        
        // Update Q values
        if (rew[i, t] == 1) {
          QMB += MB_Arew[i] * PEMB;
          QMF += MF_Arew[i] * PEMF;
        } else {
          QMB += MB_Apun[i] * PEMB;
          QMF += MF_Apun[i] * PEMF;
        }
      }
    }
  }
}
